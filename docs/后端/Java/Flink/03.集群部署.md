# 集群部署

## **集群角色**

Elink提交作业和执行任务，需要几个关键组件:
客户端(Client):代码由客户端获取并做转换，之后提交给JobManger
JobManager就是Flink集群里的“管事人”，对作业进行中央调度管理;而它获取到要执行的作业后，会进一步处理转换，然后分发任务给众多的TaskManager。
就是真正“干活的人”数据的处理操作都是它们来做的。

注意:Flink是一个非常灵活的处理框架，它支持多种不同的部署场景，还可以和不同的资源管理平台方便地集成，所以接下来我们会先做一个简单的介绍让大家有一个初步的认识，之后再展开讲述不同情形下的Flink部署。

![image-20240131143039356](assets\image-20240131143039356.png)

## **Flink集群搭建**

```
[root@localhost software]# ls
flink-1.17.0-bin-scala_2.12.tgz
[root@localhost software]# tar -zxvf flink-1.17.0-bin-scala_2.12.tgz -C /opt/module/

```

## 集群环境准备

准备三台虚拟机，命名hadoop102, hadoop103, hadoop104



### xsync方法脚本编写配置

检查有没有rsync

```
which rsync
/usr/bin/rsync
如果没有则安装：yum install rsync
```

#### 写脚本[xsync](https://so.csdn.net/so/search?q=xsync&spm=1001.2101.3001.7020).sh

脚本放到了/usr/bin目录下，并重命名为xsync,flink部署在/opt/module下了

```
vi xsync.sh
```



```
#!/bin/bash
if [ $# -lt 1 ]; then
    echo "Not Enough Argument!"
    exit
fi
# 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104; do
    echo "======= $host ======"
    
    # 遍历所有目录，挨个发送
    for file in "$@"; do
        # 判断文件是否存在
        if [ -e "$file" ]; then
            # 获取父目录
            pdir=$(cd -P "$(dirname "$file")" && pwd)
            
            # 获取当前文件的名称
            fname=$(basename "$file")
            
            ssh "$host" "mkdir -p $pdir"
            rsync -av "$pdir/$fname" "$host:$pdir"
        else
            echo "$file does not exist!"
        fi
    done
done
```

#### 配置环境变量

vi /etc/profile

\#xsync环境变量
 export PATH="/bin/xsync:$PATH"

配置完毕保存退出

#### source一下

source /etc/profile

#### 给一下权限

chmod +x /usr/bin/xsync